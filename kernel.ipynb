{
  "cells": [
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "a10f197b-9d36-4d1a-b917-90a6d28efd69",
        "_uuid": "aa268fffa8b719d737b174a38af46d1355a3fb53",
        "trusted": false
      },
      "cell_type": "code",
      "source": "import pandas as pd\n\ntrain_df=pd.read_csv('../input/train.csv')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "f15305ed-781b-43ce-b1d3-68ceb867f882",
        "_uuid": "e71e9b3f216eee3c99f55319f01aa0cc5d42cb89",
        "trusted": false
      },
      "cell_type": "code",
      "source": "train_df.head()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "aa20b8dc-1a73-4286-87ff-7e3f5cc705ea",
        "_uuid": "4d00a5785b7a049da8bd7f1f31fdb9fd4acc6e24",
        "trusted": false
      },
      "cell_type": "code",
      "source": "train_df.describe()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "bd0e020c-8eae-403e-adf7-a890ae206d5b",
        "_uuid": "10825bb6421945cf966bc966a740812700cccb0d",
        "trusted": false
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy.special import boxcox, inv_boxcox\n\nsns.boxplot(train_df['count'])\nplt.show()\n#train_df['count']=train_df['count'].apply(lambda x:np.sqrt(x))\n#train_df['count']=train_df['count'].apply(lambda x:np.sqrt(x))\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "8f33a859-5814-483d-92d1-617424e08a4d",
        "_uuid": "9a55fcee00638cc3f3858abcb40d7ea5f4b9995f"
      },
      "cell_type": "markdown",
      "source": "\nWe cannot think of any strong evidence to get rid of outlier data.\nAs per Chebychev's rule, 3 std. deviations account for 99% of data. Using this approach, we filter out the rest of the data."
    },
    {
      "metadata": {
        "_cell_guid": "d3c45f61-8631-4052-af12-405049031d50",
        "_uuid": "6486d77642dde7b2545863c38b4c143387d93ed6",
        "trusted": false
      },
      "cell_type": "code",
      "source": "\ncnt=train_df['count'].values\nq99=np.percentile(cnt,[99])\n\n\ntrain_df=train_df[train_df['count']<q99[0]]\nsns.distplot(train_df['count'])\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "c01bd6e9-d9da-4950-87ee-6ab7e1dcab78",
        "_uuid": "f199fa14356c59139ea5361fe66dc921974c0947"
      },
      "cell_type": "markdown",
      "source": "As this is a highly skewed data, we will try to transform this data using either log, square-root or box-cox  transformation.\nAfter trying out all three, log square gives the best result. Also as the evaluation metric is NLMSE, using log would help as it would allow to less penalize the large difference in final variable values."
    },
    {
      "metadata": {
        "_cell_guid": "edc2c634-4719-4360-bb87-8a0d6d96b745",
        "_uuid": "546bebeb1ab5cfea4e8b7a953e4f1568e68332e6",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#from scipy.stats import boxcox\ntrain_df['count']=train_df['count'].apply(lambda x:np.log(x))\n#train_df['count']=boxcox(train_df['count'])[0]\nsns.distplot(train_df['count'])\nplt.show()\nprint (train_df['count'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "0532a255-b6df-4995-a6c2-58013f12b73c",
        "_uuid": "39495a5aa383d480331ae2748e9504fa541848e2"
      },
      "cell_type": "markdown",
      "source": "Univariate analysis of all variables\nCategorical data--> Season, Holiday, WorkingDay, Weather"
    },
    {
      "metadata": {
        "_cell_guid": "47394552-dd99-44f1-b4be-47827dc31037",
        "_uuid": "7bc39d10d094719105d3271f73087dae023fa7d4",
        "trusted": false
      },
      "cell_type": "code",
      "source": "\n\n\n\ncat_names=['season', 'holiday', 'workingday', 'weather']\n\ni=0\nfor name in cat_names:\n    i=i+1\n    plt.subplot(2,2,i)\n    sns.countplot(name,data=train_df) \n    \nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "1a8fff98-a2bf-4fbd-83b7-34d3c31a8875",
        "_uuid": "d3803c0d83a7a186fad3cb36a56d3dbc8e84cf32"
      },
      "cell_type": "markdown",
      "source": "Univariate analysis for continuous data"
    },
    {
      "metadata": {
        "_cell_guid": "a42910c6-be94-4fb3-918d-1bf294987289",
        "_uuid": "b89209da75e0f2e71403cd40c65d3f91f7e94b37",
        "trusted": false
      },
      "cell_type": "code",
      "source": "\ncont_names=['temp','atemp','humidity','windspeed']\n\n        \n#sns.boxplot(train_df['season'])   \ni=0\nfor name in cont_names:\n    i=i+1\n    plt.subplot(2,2,i)\n    sns.boxplot(name,data=train_df) \n    \nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "b6a8cbd7-c0b8-44b2-987b-94bc40f54105",
        "_uuid": "1c5d7f72f96b7e9b3ce98320d46d046de4f7d60a"
      },
      "cell_type": "markdown",
      "source": "Some of the inferences that can be made:\n* Holiday and working day look  somewhat correlated. Can one of them be removed to avoid multi-collinearity?Let's wait until we calculate thier correlation value\n* Not much can be inferred from season data. Majority of the data fall under 1 and 2, which is clear skies mist/cloudy.\n* Temp, Atemp, humidity look normally distributed. However, windspeed has a lot of outliers which will be analysed further.\n* doing a brief time-series analysis to see if there's any improvement in count over a period of time\n* moving average to be calculated for a period of 3/4 months as that is the no of months in one season"
    },
    {
      "metadata": {
        "_cell_guid": "1347f140-3340-496b-8683-8ad40a33eda0",
        "_uuid": "8fbc30a8e72b8b2ceed313af37e13dd1577f2df7",
        "trusted": false
      },
      "cell_type": "code",
      "source": "\n\nfrom datetime import datetime\n\ntrain_df['datetime']=train_df['datetime'].apply(lambda x:datetime.strptime(x,'%Y-%m-%d %H:%M:%S'))\ntime_series_df=train_df\ntime_series_df.index=train_df['datetime']\n\nimport matplotlib.pyplot as plt\n\n#Applying rolling average on a period of 60 days, as the typical weather lasts for around 3 months (20 days in training data of each month)\nplt.plot(pd.rolling_mean(time_series_df['count'],60))\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "0857e5e4-0be1-4923-bf8f-b8843f3cd2a3",
        "_uuid": "c65372c20bcdb27250a1a1914a8af3252f6f3aab"
      },
      "cell_type": "markdown",
      "source": "As expected the total count grows over a period of time following an increasing cyclic pattern, therefore the model needs to incorporate changes in seasonality too, for which we would be using the month and year variables."
    },
    {
      "metadata": {
        "_cell_guid": "f8a92350-807e-4657-9ff1-8b0afdcbfcd8",
        "_uuid": "656b4f0113f75520a8b28e9d891a2cf382003d6e"
      },
      "cell_type": "markdown",
      "source": "Biivariate analysis on continuous data"
    },
    {
      "metadata": {
        "_cell_guid": "cdcd5945-694c-44bb-aa61-2ccd4f25cda8",
        "_uuid": "8bf4bba0ceb8db29509d41460b9f0a96cdf07f2d",
        "trusted": false
      },
      "cell_type": "code",
      "source": "\ni=1\nfor name_1 in cont_names:\n    j=cont_names.index(name_1)\n\n\n    while(j<len(cont_names)-1):\n\n\n        plt.subplot(6,1,i)\n        plt.title(name_1+' vs '+cont_names[j+1])\n        sns.jointplot(x=name_1,y=cont_names[j+1],data=train_df) \n        j=j+1\n        i=i+1\n        plt.show()\n            \n    \n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "d69a8a9c-1050-41f3-ac08-fd571a11b337",
        "_uuid": "6d7a46c94d805f7a09a13c3d981239927e187c29"
      },
      "cell_type": "markdown",
      "source": "Not much can be inferred about the distribution of these variables except for variable 'temp' and 'atemp' that almost have\nsimilar context. We would be using the 'temp' and getting rid of the 'atemp' variables for better precision value and avoiding \nmulti-collinearity.\n\n"
    },
    {
      "metadata": {
        "_cell_guid": "c8267692-d43f-411e-b00f-928d5f869dfa",
        "_uuid": "d637d8d018049071f7b62a96439be3668e262c6e"
      },
      "cell_type": "markdown",
      "source": "Let us perfrom some feature engineering. The datetime column can be used to extract data like the month, day, hour which can be\nused in our model for making better predictions."
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "751c6fcd-8811-48c5-902b-e7c020aa4498",
        "_uuid": "6a023b875cd5464845950f13f390cfe25fe7672e",
        "trusted": false
      },
      "cell_type": "code",
      "source": "\n\nfrom datetime import datetime\n\n#converting string dattime to datetime\n\n\n#train_df['datetime']=train_df['datetime'].apply(lambda x:datetime.strptime(x,'%Y-%m-%d %H:%M:%S'))\n\nnew_df=train_df\n\nnew_df['month']=new_df['datetime'].apply(lambda x:x.month)\nnew_df['hour']=new_df['datetime'].apply(lambda x:x.hour)\nnew_df['day']=new_df['datetime'].apply(lambda x:x.day)\nnew_df['year']=new_df['datetime'].apply(lambda x:x.year)\n#new_df['weekday_flag']=new_df['datetime'].apply(weekday_flag)\nnew_df['mnth+day']=new_df['datetime'].apply(lambda x:str(x.month)+'_'+str(x.day))\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "d7b54b7d-d112-46ba-ac36-b1e83c0fa27e",
        "_uuid": "71a3e1dd2108be2dd7cadddff203d7e7cd0865a7",
        "trusted": false
      },
      "cell_type": "code",
      "source": "sns.swarmplot(x='hour',y='temp',data=new_df,hue='season')\nplt.show()\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "78aa3015-6f68-47f4-b327-a0f385b45937",
        "_uuid": "2ba7887a0dc7cc940d64cee67f4b95cfbeb3f943"
      },
      "cell_type": "markdown",
      "source": "A non-linear relationship between temperature and day of the hour according to different seasons is evident from this chart.\nFeature engineering to create bins on an hourly basis.\n"
    },
    {
      "metadata": {
        "_cell_guid": "3dbbca58-5be7-442b-bfb0-042f53c525e7",
        "_uuid": "1ec482e5f9b179fe0bcda7ac5e0e05a56e2e18de",
        "trusted": false
      },
      "cell_type": "code",
      "source": "new_df.cov()\nsns.heatmap(new_df.corr())\nplt.show()\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "14e60325-b201-4942-9cd4-70453ffa58ba",
        "_uuid": "b2147f33f5250752f211fa698ac3c44f2485d8c8"
      },
      "cell_type": "markdown",
      "source": "A lot of inferences that we have already covered could be verified using the following heatmap"
    },
    {
      "metadata": {
        "_cell_guid": "c4662813-40f7-4afb-8926-efd578d3ba9a",
        "_uuid": "ff10dd17efe07da8c5b42f4574aad1d7e9bf812f",
        "trusted": false
      },
      "cell_type": "code",
      "source": "new_df.corr()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "8b771d1c-e072-4420-836d-44e491aeb141",
        "_uuid": "14497541fdb351b0902c9ccc15570aa075943221"
      },
      "cell_type": "markdown",
      "source": "A lot of inferences that we have already hypothesised could be verified using the following heatmap and correlation matrix.\n\nVisualizing multi-variate distribution of target variable with other categorical data."
    },
    {
      "metadata": {
        "_cell_guid": "edc63557-c6ac-42aa-b7dd-1ffacafdcab0",
        "_uuid": "a691c6e63163593c5582ece41e65a5305c6bf58c",
        "trusted": false
      },
      "cell_type": "code",
      "source": "\ncat_names=['season', 'holiday', 'workingday', 'weather']\ni=1\nfor name in cat_names:\n    plt.subplot(2,2,i)\n    sns.barplot(x=name,y='count',data=new_df,estimator=sum)\n    i=i+1\n    plt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "1329487e-2047-4e2f-b370-a4f236295b4c",
        "_uuid": "fbf09e9c79d22e82c6d49155a81cfbf0b74f4a5b"
      },
      "cell_type": "markdown",
      "source": "*  With weather 1,2 and season 2,3 and working days the bicycle rental count is maximum.\n*  As per the analysis, we need to get rid off these variables to be inputted in our model:season. Working day has better correlation with count, weather,working day, hour,year has to be label encoded"
    },
    {
      "metadata": {
        "_cell_guid": "69d4f5ed-fafc-4fa4-a5cf-0b43b9f7e48c",
        "_uuid": "76de4d76f0e42730669088304a516cdb910c7bcd",
        "trusted": false
      },
      "cell_type": "code",
      "source": "\n\n\nfinal_df=new_df.drop(['datetime','temp','windspeed','casual','registered','mnth+day','day'], axis=1)\nfinal_df.head()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "726c880d-0501-4571-9c13-5a256e40b1a0",
        "_uuid": "44c286f11ad63864738cd68032e6ef5d69daa319"
      },
      "cell_type": "markdown",
      "source": "Adding dummy varibles to categorical data"
    },
    {
      "metadata": {
        "_cell_guid": "6686d7b4-2409-4268-8311-da54db08ee32",
        "_uuid": "4bcca1edc256feb52b843bca14c9b95abbb46a49",
        "trusted": false
      },
      "cell_type": "code",
      "source": "\nweather_df=pd.get_dummies(new_df['weather'],prefix='w',drop_first=True)\nyear_df=pd.get_dummies(new_df['year'],prefix='y',drop_first=True)\nmonth_df=pd.get_dummies(new_df['month'],prefix='m',drop_first=True)\nhour_df=pd.get_dummies(new_df['hour'],prefix='h',drop_first=True)\nseason_df=pd.get_dummies(new_df['season'],prefix='s',drop_first=True)\n                     \n\n\nfinal_df=final_df.join(weather_df)\nfinal_df=final_df.join(year_df)\nfinal_df=final_df.join(month_df)                     \nfinal_df=final_df.join(hour_df)\nfinal_df=final_df.join(season_df)\n                     \nfinal_df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "1f48c74d-52b7-4737-bba9-c9622975b0c1",
        "_uuid": "ff47fe6a2e7860901474cba476763e9f92ea3ddc",
        "trusted": false
      },
      "cell_type": "code",
      "source": "final_df.columns",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "44082e61-1e78-4a3b-b36b-4a2c586555bb",
        "_uuid": "124c31b27dadccdcff834eedac3e57404007215f"
      },
      "cell_type": "markdown",
      "source": "Now that we have got our guns lock and loaded, it's time to shoot.\nlets begin the modelling process.\n"
    },
    {
      "metadata": {
        "_cell_guid": "449cf6b2-ed41-43d9-a096-5644f42372b5",
        "_uuid": "e473b1caa4540f1a80339e31af7137c7deb7c6c4",
        "trusted": false
      },
      "cell_type": "code",
      "source": "\n\nX=final_df.iloc[:,final_df.columns!='count'].values\nprint (X)\n\nY=final_df.iloc[:,6].values\n\nprint (Y)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "a16d65b8-187e-4433-b004-085343f13d00",
        "_uuid": "9451f2066e46ed46551347d21537b4c0b031ea15"
      },
      "cell_type": "markdown",
      "source": "**Choosing the appropriate model for regression**\nAfter trying multiple linear regression, poly linear regression, SVR, Decision Tree regression and RF regression,XGRegressor\nOut of these, we would be choosing the one having the best accuracy and applying GridSearchCV for optimal hyperparmater tuning. XGBoost gives the maximum accuracy of R2 square (92.5%)"
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "ac982002-02ab-4efe-8e5f-8d939737d143",
        "_uuid": "1799377561f5d1a49c03c0902180c161d350f1d4",
        "trusted": false
      },
      "cell_type": "code",
      "source": "\n\nimport xgboost as xg\nfrom sklearn.model_selection import GridSearchCV\n\ndef grid_search():\n    print ('lets go')\n\n    xgr=xg.XGBRegressor(max_depth=8,min_child_weight=6,gamma=0.4)\n    xgr.fit(X,Y)\n\n    #rf=RandomForestRegressor(n_estimators=100,random_state=0)\n    #rf.fit(X,Y)\n\n    \n    #parameters=[{'max_depth':[8,9,10,11,12],'min_child_weight':[4,5,6,7,8]}]\n    #parameters=[{'gamma':[i/10.0 for i in range(0,5)]}]\n    parameters=[{'subsample':[i/10.0 for i in range(6,10)],\n 'colsample_bytree':[i/10.0 for i in range(6,10)]}]\n\n    grid_search= GridSearchCV(estimator=xgr, param_grid=parameters, cv=10,n_jobs=-1)\n\n\n    print (1)\n    grid_search=grid_search.fit(X,Y)\n    print (2)\n    best_accuracy=grid_search.best_score_\n    best_parameters=grid_search.best_params_\n    print (best_accuracy)\n    print (best_parameters)\n\n\n\n#if __name__ == '__main__':\n   #grid_search()\n\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "03003699-f011-4874-a495-c05cb51c04a1",
        "_uuid": "fd3047e6adb1fa6fd62db5fb7c5e91d60b0270e8"
      },
      "cell_type": "markdown",
      "source": "Grid search gives best accuracy for max_depth=8,min_child_weight=6,gamma=0.4,colsample_bytree=0.6,subsample=0.6\nTraining the model again with these new parameters."
    },
    {
      "metadata": {
        "_uuid": "f9eb30ae7194bbdf18f9878a9888ff99f435b61e",
        "trusted": false
      },
      "cell_type": "code",
      "source": "from sklearn.ensemble import RandomForestRegressor\nrf=RandomForestRegressor(n_estimators=100,random_state=0)\nrf.fit(X,Y)\nimp_list=rf.feature_importances_\nfeats = {} # a dict to hold feature_name: feature_importance\nfor feature, importance in zip(final_df.columns, rf.feature_importances_):\n    feats[feature] = importance #add the name/value pair ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "65d80e11f913870b2836a8c64a6e25366071ca08",
        "trusted": false
      },
      "cell_type": "code",
      "source": "import operator\nsorted_x = sorted(feats.items(), key=operator.itemgetter(1),reverse=True)\nprint (sorted_x)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "e148caf9-239a-4153-877a-ec9c7f3d5c4c",
        "_uuid": "58e2255118b8bc091d370cf52d346263fd61ccfe",
        "trusted": false
      },
      "cell_type": "code",
      "source": "\nimport xgboost as xg\nxgr=xg.XGBRegressor(max_depth=8,min_child_weight=6,gamma=0.4,colsample_bytree=0.6,subsample=0.6)\nxgr.fit(X,Y)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "5b8f5240-cb4f-414a-a99e-cc2633d6af51",
        "_uuid": "1d83d9a2c55442e2c26da9c945370b01f7a8e684"
      },
      "cell_type": "markdown",
      "source": "Using the same pre-processing functions on the test data:"
    },
    {
      "metadata": {
        "_cell_guid": "70a1d9d3-b097-411c-8823-0c4ae587c052",
        "_uuid": "3bebcb9054f96dc9a04c01b5fbb5a87d5e61ee87",
        "trusted": false
      },
      "cell_type": "code",
      "source": "\n\nnew_df=pd.read_csv('../input/test.csv')\nnew_df['datetime']=new_df['datetime'].apply(lambda x:datetime.strptime(x,'%Y-%m-%d %H:%M:%S'))\n\n\nnew_df['month']=new_df['datetime'].apply(lambda x:x.month)\nnew_df['hour']=new_df['datetime'].apply(lambda x:x.hour)\nnew_df['day']=new_df['datetime'].apply(lambda x:x.day)\nnew_df['year']=new_df['datetime'].apply(lambda x:x.year)\n#new_df['weekday_flag']=new_df['datetime'].apply(weekday_flag)\n#new_df['mnth+day']=new_df['datetime'].apply(lambda x:str(x.month)+'_'+str(x.day))\n\nprint (new_df.head())\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "822cbf81-5b24-4013-b3f7-030e3fe39cf1",
        "_uuid": "50e4fab08658d44b2965e6788eb21283a3f30676",
        "trusted": false
      },
      "cell_type": "code",
      "source": "\nnew_df=new_df.drop(['datetime','temp','windspeed','day'], axis=1)\nnew_df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "b0edf90e-1dab-4b71-892d-e2dc58015dd2",
        "_uuid": "a8767f34e1d8e70e8a7278c92f32d6a2c76c3088",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#adding dummy varibles to categorical variables\nweather_df=pd.get_dummies(new_df['weather'],prefix='w',drop_first=True)\nyr_df=pd.get_dummies(new_df['year'],prefix='y',drop_first=True)\nmonth_df=pd.get_dummies(new_df['month'],prefix='m',drop_first=True)\nhour_df=pd.get_dummies(new_df['hour'],prefix='h',drop_first=True)\nseason_df=pd.get_dummies(new_df['season'],prefix='s',drop_first=True)\n\n\nnew_df=new_df.join(weather_df)\nnew_df=new_df.join(yr_df)\nnew_df=new_df.join(month_df)                     \nnew_df=new_df.join(hour_df)\nnew_df=new_df.join(season_df)\n                     \nnew_df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "bc401bed-bfba-4fc3-a872-827cc5730e1b",
        "_uuid": "58f606b5fd3b2867fbca85ff11d207b20312f13f",
        "trusted": false
      },
      "cell_type": "code",
      "source": "X_test=new_df.iloc[:,:].values\nX_test.shape\n#print (new_df.columns)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "433a2023-7df1-47d0-be40-84aefb40f740",
        "_uuid": "f53dda9c610d09822c8626063f53133c14b054cc"
      },
      "cell_type": "markdown",
      "source": "Using the XGBoost Regressor for predictions:"
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "5a3b73b1-bec8-4e59-bc4e-9319d4502716",
        "_uuid": "f4b4d570d430e9d7196ec92b20d8bd2cc5c72bf0",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#def invboxcox(y):\n#    return(np.exp(np.log(0.69*y+1)/0.69))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "3f3d3c82-d1eb-42dc-93dc-fc7d2b9f6c99",
        "_uuid": "e8d292d719e755e54cae357ff6b2ab9bcc6f28bf",
        "trusted": false
      },
      "cell_type": "code",
      "source": "y_output=xgr.predict(X_test)\ny_output\n\n\n\n\nop=pd.DataFrame({'count':np.exp(y_output)})\nop.to_csv('sub1.csv')\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "c1ac041a-1085-49ed-935b-53f69931bfac",
        "_uuid": "d6ea47ce24d8f87cdd03deab6e8ba1dd520199f4",
        "trusted": false
      },
      "cell_type": "code",
      "source": "print (np.exp(y_output))",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "name": "python",
      "mimetype": "text/x-python",
      "file_extension": ".py",
      "nbconvert_exporter": "python",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      },
      "version": "3.6.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}